{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://nlpforhackers.io/wordnet-sentence-similarity/\n",
    "#https://realpython.com/python-csv/\n",
    "#import re\n",
    "import csv\n",
    "import json\n",
    "#import ijson\n",
    "#import bisect\n",
    "import gensim\n",
    "import nltk\n",
    "#import _thread\n",
    "#import threading\n",
    "#from multiprocessing import Pool\n",
    "from multiprocessing.pool import ThreadPool\n",
    "#from threading import Thread\n",
    "#import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import scipy.interpolate as interpolate\n",
    "from operator import itemgetter\n",
    "from scipy import stats\n",
    "from itertools import groupby\n",
    "from collections import Counter\n",
    "#from gensim.models import LdaModel\n",
    "#from stop_words import get_stop_words\n",
    "from nltk import pos_tag\n",
    "from IPython.display import clear_output\n",
    "#from nltk.corpus import stopwords as nltk_stop_words, wordnet as wn\n",
    "#from nltk.tokenize import RegexpTokenizer\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "#from scipy.interpolate import spline\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "folder_path = 'D:/MS CS/RS DATA/dataset/StarRank/'\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-authors number of common papers (Just Count)\n",
    "#### -> Read authors id\n",
    "#### -> Check their number of co-authors and build coupus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_aid = []\n",
    "with open(folder_path+'author-corpus.json','r', encoding=\"utf8\") as f:\n",
    "    for doc in f:\n",
    "        author_aid.append(json.loads(doc)['aid'])\n",
    "    f.close()\n",
    "    \n",
    "    coauthor_common_paper = pd.read_csv(folder_path+'AMiner-Coauthor.txt', sep='\\t', names=['aid', 'co_aid', 'common_paper'])\n",
    "    coauthor_common_paper['aid'] = (coauthor_common_paper['aid'].str.replace('#','')).astype(str).astype(int)\n",
    "    coauthor_common_paper = coauthor_common_paper[coauthor_common_paper['aid'].isin(author_aid)]\n",
    "    coauthor_common_paper.to_csv(folder_path+'coauthor_common_paper.csv', sep=',', encoding='utf-8', index=False)\n",
    "    coauthor_common_paper.head()\n",
    "    print(\"Success...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_to_paper = pd.read_json(folder_path+'author-2-paper.json', orient='records', encoding='utf8', lines=True)\n",
    "author_to_paper_pid_grouped = author_to_paper.groupby(\"pid\")\n",
    "unique_author = list(set(author_to_paper['aid']))\n",
    "print(\"Success...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile_acw = open(folder_path+'acw.csv', 'w+', encoding='utf8', newline='')\n",
    "acw_writer = csv.writer(outfile_acw)\n",
    "\n",
    "def calWSC(first_auth):\n",
    "    for second_auth in unique_author:\n",
    "        if first_auth != second_auth:\n",
    "            data = []\n",
    "            ac_lk = 0.0\n",
    "            pac_k = 0.0\n",
    "            for pid, doc in author_to_paper_pid_grouped:\n",
    "                aid = list(doc['aid'])\n",
    "                second_auth_aid = False\n",
    "                if second_auth in aid:\n",
    "                    pac_k += (1/int(doc[doc.aid == second_auth]['pos']))\n",
    "                    second_auth_aid = True\n",
    "                if second_auth_aid and first_auth in aid:\n",
    "                    ac_lk += (1/int(doc[doc.aid == first_auth]['pos']))\n",
    "                    ac_lk += (1/int(doc[doc.aid == second_auth]['pos']))\n",
    "                \n",
    "            clear_output()\n",
    "            print('first_auth',first_auth,'second_auth', second_auth, 'ACW', (ac_lk/pac_k))\n",
    "            data.append(first_auth)\n",
    "            data.append(second_auth)\n",
    "            data.append((ac_lk/pac_k))\n",
    "            acw_writer.writerow(data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    acw_writer.writerow(['first_auth', 'second_auth', 'acw'])\n",
    "    pool = ThreadPool(16)\n",
    "    pool.map(calWSC, unique_author)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    #pd.DataFrame(author_score).to_json(folder_path+'acw.json', orient='records', lines=True)\n",
    "    print('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"a\",\"a\",\"a\",\"b\",\"b\",\"b\"]\n",
    "\n",
    "stats.entropy(list(Counter(labels).values()), base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prs_corpus = pd.read_json(folder_path+'prs-corpus.json', orient='records', encoding='utf8', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unList(prs_corpus[prs_corpus.id==821833]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder_path+'rs-corpus.json', 'r', encoding='utf8') as f:\n",
    "    rs_corpus = []\n",
    "    for doc in f:\n",
    "        data = json.loads(doc)\n",
    "        del data['authors']\n",
    "        del data['vas']\n",
    "        del data['year']\n",
    "        data['title'] = list(chain(*prs_corpus[prs_corpus.id==data['id']]['title']))\n",
    "        rs_corpus.append(data)\n",
    "    f.close()\n",
    "    rs_corpus = pd.DataFrame(rs_corpus)\n",
    "    rs_corpus.to_json(folder_path+'star-rs-corpus.json', orient='records', lines=True)\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prs_corpus = []\n",
    "with open(folder_path+'preprocessed-corpus.json', 'r', encoding='utf8') as f:\n",
    "    for doc in f:\n",
    "        data = json.loads(doc)\n",
    "        for year in data:\n",
    "            for rec in data[year]:\n",
    "                prs_corpus.append(rec)\n",
    "    f.close()\n",
    "    prs_corpus = pd.DataFrame(prs_corpus)\n",
    "    #prs_corpus.to_json(folder_path+'star-rs-corpus.json', orient='records', lines=True)\n",
    "    print (\"preprocessed-corpus successfully loaded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(chain(*data['title'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
