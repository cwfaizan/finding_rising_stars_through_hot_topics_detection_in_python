{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://nlpforhackers.io/wordnet-sentence-similarity/\n",
    "#https://realpython.com/python-csv/\n",
    "\n",
    "#import _thread\n",
    "#import threading\n",
    "#from multiprocessing.pool import ThreadPool\n",
    "#from threading import Thread\n",
    "#import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import scipy.interpolate as interpolate\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "from IPython.display import clear_output\n",
    "folder_path = 'E:/MS CS/RS DATA/dataset/StarRank/'\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_to_paper = pd.read_json(folder_path+'author-2-paper.json', orient='records', encoding='utf8', lines=True)\n",
    "common_paper = pd.merge(author_to_paper, author_to_paper, on=['pid'], how='inner', suffixes=(\"l\", \"k\"))\n",
    "distinct_common_paper = common_paper[common_paper.aidk != common_paper.aidl]\n",
    "distinct_common_paper_grouped = distinct_common_paper.groupby(\"aidl\")\n",
    "\n",
    "rs_corpus = pd.read_json(folder_path+'rs-corpus.json', orient='records', encoding='utf8', lines=True)\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AOWI_score = []\n",
    "\n",
    "for k_aidk, v_aidk in distinct_common_paper.groupby(\"aidk\"):\n",
    "    \n",
    "    clear_output()\n",
    "    pao_k = 0\n",
    "    # Authors’ Papers & Order of Appearance.\n",
    "    for pos in v_aidk['posk'].unique():\n",
    "        pao_k = pao_k + (1/pos)\n",
    "        \n",
    "    for k_aidl, v_aidl in v_aidk.groupby(\"aidl\"):\n",
    "        \n",
    "        ao_l_k = 0\n",
    "        # Authors’ Papers & Order of Appearance.\n",
    "        for index, common_paper in v_aidl.iterrows():\n",
    "            ao_l_k = ao_l_k + (1/common_paper['posl']) + (1/common_paper['posk'])\n",
    "    \n",
    "        # Co-Author Order based Mutual Influence\n",
    "        AOWI = ao_l_k/pao_k\n",
    "        AOWI_score.append([k_aidl, k_aidk, AOWI])\n",
    "        print(k_aidl, k_aidk, AOWI)\n",
    "        \n",
    "print(\"saving\")\n",
    "pd.DataFrame(AOWI_score).to_csv(folder_path+'AOWI-score.csv', sep=',', encoding='utf-8', header=None, index=False)\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_entropy = []\n",
    "\n",
    "for k_venue, v_venue in rs_corpus.groupby(\"venue\"):\n",
    "    clear_output()\n",
    "    print(k_venue)\n",
    "    \n",
    "    venue_entropy.append([k_venue, stats.entropy(list(Counter(list(chain(*v_venue['title']))).values()), base=2)])\n",
    "\n",
    "print(\"saving\")\n",
    "pd.DataFrame(venue_entropy).to_csv(folder_path+'venue-entropy.csv', sep=',', encoding='utf-8', header=None, index=False)\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publication_quality_score = []\n",
    "damping_factor = 0.85\n",
    "for author, papers in author_to_paper.groupby(\"aid\"):\n",
    "    \n",
    "    clear_output()\n",
    "    print(author)\n",
    "    total_entropy = 0.0\n",
    "    for venue_id in rs_corpus[rs_corpus.id.isin(papers['pid'])]['venue']:\n",
    "        \n",
    "        entropy = float(venue_entropy[venue_entropy.venue==venue_id]['entropy'])\n",
    "        total_entropy = total_entropy + (1.0/(damping_factor**entropy))\n",
    "        \n",
    "    publication_quality_score.append([author, (total_entropy / float(papers['pid'].nunique()))])\n",
    "\n",
    "print(\"saving\")\n",
    "pd.DataFrame(publication_quality_score).to_csv(folder_path+'publication-quality-score.csv', sep=',', encoding='utf-8', header=None, index=False)\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AOWI_score = pd.read_csv(folder_path+'AOWI-score.csv', names=['aidi', 'aidj', 'AOWI'])\n",
    "publication_quality_score = pd.read_csv(folder_path+'publication-quality-score.csv', names=['aidi', 'dpq'])\n",
    "star_score = pd.merge(AOWI_score, publication_quality_score, on=['aidi'], how='inner')\n",
    "star_score_grouped = star_score.groupby('aidi')\n",
    "\n",
    "author_corpus = pd.read_json(folder_path+'author-corpus.json', orient='records', encoding='utf8', lines=True)\n",
    "author_id = author_corpus['aid'].unique().tolist()\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(author_id)\n",
    "d = 0.85\n",
    "star_rank = []\n",
    "\n",
    "for v_aidi in author_id:\n",
    "    \n",
    "    clear_output()\n",
    "    print(v_aidi)\n",
    "    T_score = 0.0\n",
    "    vocabulary_co_author = star_score_grouped.get_group(v_aidi)\n",
    "    for index_j, v_aidj in vocabulary_co_author.iterrows():\n",
    "        \n",
    "        upper_T = (float(v_aidj.AOWI)*float(v_aidj.dpq))\n",
    "        lower_T = 0.0\n",
    "        for index_k, v_aidk in vocabulary_co_author.iterrows():\n",
    "            \n",
    "            lower_row = star_score[(star_score.aidi == v_aidk.aidi) & (star_score.aidj == v_aidj.aidj)]\n",
    "            lower_T = lower_T + (float(lower_row.AOWI)*float(lower_row.dpq))\n",
    "            \n",
    "        T_score = T_score + (upper_T/(lower_T+1))\n",
    "    \n",
    "    star_rank.append([v_aidi, (((1-d)/n) + (d*T_score))])\n",
    "\n",
    "print(\"saving\")\n",
    "pd.DataFrame(star_rank).to_csv(folder_path+'star-rank-85.csv', sep=',', encoding='utf-8', header=None, index=False)\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_rank = pd.read_csv(folder_path+'star-rank-85.csv', names=['aid', 'score'])\n",
    "star_rank.sort_values(by=['score'], inplace=True, ascending=False)\n",
    "star_rank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"a\",\"a\",\"a\",\"b\",\"b\",\"b\"]\n",
    "\n",
    "stats.entropy(list(Counter(labels).values()), base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prs_corpus = pd.read_json(folder_path+'prs-corpus.json', orient='records', encoding='utf8', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unList(prs_corpus[prs_corpus.id==821833]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder_path+'rs-corpus.json', 'r', encoding='utf8') as f:\n",
    "    rs_corpus = []\n",
    "    for doc in f:\n",
    "        data = json.loads(doc)\n",
    "        del data['authors']\n",
    "        del data['vas']\n",
    "        del data['year']\n",
    "        data['title'] = list(chain(*prs_corpus[prs_corpus.id==data['id']]['title']))\n",
    "        rs_corpus.append(data)\n",
    "    f.close()\n",
    "    rs_corpus = pd.DataFrame(rs_corpus)\n",
    "    rs_corpus.to_json(folder_path+'star-rs-corpus.json', orient='records', lines=True)\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prs_corpus = []\n",
    "with open(folder_path+'preprocessed-corpus.json', 'r', encoding='utf8') as f:\n",
    "    for doc in f:\n",
    "        data = json.loads(doc)\n",
    "        for year in data:\n",
    "            for rec in data[year]:\n",
    "                prs_corpus.append(rec)\n",
    "    f.close()\n",
    "    prs_corpus = pd.DataFrame(prs_corpus)\n",
    "    #prs_corpus.to_json(folder_path+'star-rs-corpus.json', orient='records', lines=True)\n",
    "    print (\"preprocessed-corpus successfully loaded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(chain(*data['title'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
