{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://nlpforhackers.io/wordnet-sentence-similarity/\n",
    "#https://realpython.com/python-csv/\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import ijson\n",
    "import bisect\n",
    "import gensim\n",
    "import nltk\n",
    "#import _thread\n",
    "#import threading\n",
    "#from multiprocessing import Pool\n",
    "from multiprocessing.pool import ThreadPool\n",
    "#from threading import Thread\n",
    "#import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import scipy.interpolate as interpolate\n",
    "from operator import itemgetter\n",
    "from scipy import stats\n",
    "from itertools import groupby\n",
    "from collections import Counter\n",
    "#from gensim.models import LdaModel\n",
    "#from stop_words import get_stop_words\n",
    "from nltk import pos_tag\n",
    "from IPython.display import clear_output\n",
    "#from nltk.corpus import stopwords as nltk_stop_words, wordnet as wn\n",
    "#from nltk.tokenize import RegexpTokenizer\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "#from scipy.interpolate import spline\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path where files reside\n",
    "folder_path = 'E:/MS CS/RS DATA/dataset/'\n",
    "#folder_path = 'E:/MS CS/RS DATA/aminer_authors_3/'\n",
    "#folder_path = 'E:/MS CS/RS DATA/dblp-ref/'\n",
    "\n",
    "print(\"All variables have initialized...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_to_paper = pd.read_json(folder_path+'author-2-paper.json', orient='records', encoding='utf8', lines=True)\n",
    "aid_list = list(set(author_to_paper['aid']))\n",
    "aid_len = len(aid_list)\n",
    "\n",
    "groupby_aid_author_to_paper = author_to_paper.groupby(\"aid\")\n",
    "#groupby_pid_author_to_paper = author_to_paper.groupby(\"pid\")\n",
    "\n",
    "rs_corpus = pd.read_json(folder_path+'rs-corpus.json', orient='records', encoding='utf8', lines=True)\n",
    "author_corpus = pd.read_json(folder_path+'author-corpus.json', orient='records', encoding='utf8', lines=True)\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cac_k_l -> number of co-authored citations of papers for Author L and K\n",
    "#### tac_k -> total numbers of citations of authors K\n",
    "\n",
    "\n",
    "#### fap_k -> common papers written by K as 1st author\n",
    "#### fap_l -> common papers written by L as 1st author\n",
    "#### tap_k -> total papers written by author K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_paper_citation = []\n",
    "total_citation = []\n",
    "common_paper_weight = []\n",
    "paper_weight = []\n",
    "\n",
    "def get_WMIRank(i):\n",
    "    clear_output()\n",
    "    print(i)\n",
    "    aid_k = aid_list[i]\n",
    "    author_a = groupby_aid_author_to_paper.get_group(aid_k)\n",
    "    tac_k = sum(rs_corpus[rs_corpus['id'].isin(list(set(author_a['pid'])))]['citation'])\n",
    "    tap_k = len(author_a)\n",
    "    \n",
    "    total_citation.append([aid_k, tac_k])\n",
    "    #print(aid_k, tac_k)\n",
    "    paper_weight.append([aid_k, tap_k])\n",
    "    #print(aid_k, tap_k)\n",
    "    #print('--------------------')\n",
    "    for j in range(i+1, aid_len):\n",
    "        aid_l = aid_list[j]\n",
    "        author_b = groupby_aid_author_to_paper.get_group(aid_l)\n",
    "        tap_l = len(author_b)\n",
    "        common_paper = list(set(author_a['pid']) & set(author_b['pid']))\n",
    "        \n",
    "        if len(common_paper)>0:\n",
    "            cac_k_l = sum(rs_corpus[rs_corpus['id'].isin(common_paper)]['citation'])\n",
    "            fap_k = len(author_a[author_a['pos']==1]['pid'].isin(common_paper))\n",
    "            fap_l = len(author_b[author_b['pos']==1]['pid'].isin(common_paper))\n",
    "            \n",
    "            common_paper_citation.append([aid_l, aid_k, cac_k_l])\n",
    "            #print(aid_l, aid_k, cac_k_l)\n",
    "            common_paper_weight.append([aid_l, aid_k, fap_l, fap_k])\n",
    "            #print(aid_l, aid_k, fap_l, fap_k)\n",
    "            \n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    jobs = []\n",
    "    for index in range(0, aid_len):\n",
    "        jobs.append(index)\n",
    "        \n",
    "    pool = ThreadPool(32)\n",
    "    print(\"Preprocessing has been started...\")\n",
    "    pool.starmap(get_WMIRank, zip(jobs))\n",
    "    print('Topics completed...')\n",
    "    pool.close() \n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(common_paper_citation).to_csv(folder_path+'common-paper-citation.csv', sep=',', encoding='utf-8', header=None, index=False)\n",
    "pd.DataFrame(total_citation).to_csv(folder_path+'total-citation.csv', sep=',', encoding='utf-8', header=None, index=False)\n",
    "pd.DataFrame(common_paper_weight).to_csv(folder_path+'common-paper-weight.csv', sep=',', encoding='utf-8', header=None, index=False)\n",
    "pd.DataFrame(paper_weight).to_csv(folder_path+'paper-weight.csv', sep=',', encoding='utf-8', header=None, index=False)\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from itertools import product\n",
    "\n",
    "def merge_names(a, b):\n",
    "    return '{} & {}'.format(a, b)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    names = ['Brown', 'Wilson', 'Bartlett', 'Rivera', 'Molloy', 'Opie']\n",
    "    with multiprocessing.Pool(processes=3) as pool:\n",
    "        results = pool.map(merge_names, product(names, repeat=2))\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4, 5]\n",
    "b = [4, 8, 7, 6, 5]\n",
    "c = a+b\n",
    "print(\"common\",list(set(a) & set(b)))\n",
    "print(\"diff in a\",list(set(a) - set(b)))\n",
    "print(\"diff in b\",list(set(b) - set(a)))\n",
    "print(\"c\",list(set(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([1,2,3,4,2,5])\n",
    "match_index = df.isin([1,2])\n",
    "print(match_index)\n",
    "ab = ['0','1','2','3','4','5']\n",
    "index = [ab[i] for i in range(len(match_index)) if match_index[0][i]]\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete extra data from rs-curpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_corpus = []\n",
    "with open(folder_path+'rs-corpus.json','r', encoding=\"utf8\") as f:\n",
    "    for doc in f:\n",
    "        data = json.loads(doc)\n",
    "        del data['abstract']\n",
    "        del data['affiliations']\n",
    "        del data['references']\n",
    "        del data['title']\n",
    "        rs_corpus.append(data)\n",
    "    f.close()\n",
    "print(\"dataset loaded...!!\")\n",
    "pd.DataFrame(rs_corpus).to_json(folder_path+'rs-corpus.json', orient='records', lines=True)\n",
    "print(\"success\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
